{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cedc37c",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639928ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Data processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "# LightGBM is a gradient boosting framework that uses tree based learning algorithms\n",
    "import lightgbm as lgb\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Fairlearn algorithms and utils\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.reductions import GridSearch, EqualizedOdds\n",
    "\n",
    "# Metrics\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    selection_rate, demographic_parity_difference, demographic_parity_ratio,\n",
    "    true_positive_rate, false_positive_rate, false_negative_rate,\n",
    "    false_positive_rate_difference, false_negative_rate_difference,\n",
    "    equalized_odds_difference)\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import selection_rate, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26eda5d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>action_taken</th>\n",
       "      <th>preapproval_requested</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>interest_only_payment</th>\n",
       "      <th>balloon_payment</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loan_to_value_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  race  gender  action_taken  preapproval_requested  loan_type  \\\n",
       "0          0     1       1             1                      0          1   \n",
       "1          0     1       1             0                      0          1   \n",
       "2          1     1       1             1                      0          1   \n",
       "3          0     1       1             1                      0          1   \n",
       "4          1     1       0             1                      0          1   \n",
       "\n",
       "   loan_purpose  interest_only_payment  balloon_payment  debt_to_income_ratio  \\\n",
       "0             1                      2                2                     4   \n",
       "1             3                      2                2                     4   \n",
       "2             1                      2                2                     4   \n",
       "3             1                      2                2                     1   \n",
       "4             1                      2                2                     4   \n",
       "\n",
       "   age  income  loan_to_value_ratio  \n",
       "0    1       2                    3  \n",
       "1    2       2                    1  \n",
       "2    2       3                    1  \n",
       "3    3       3                    3  \n",
       "4    2       4                    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the clean data\n",
    "d = 'Fairlearn_TX_Waco.csv'\n",
    "d = pd.read_csv(d, sep = ',')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9abb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e19f9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2071 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      race  ethnicity\n",
       "0        1          1\n",
       "1        1          1\n",
       "2        1          0\n",
       "3        1          1\n",
       "4        1          0\n",
       "...    ...        ...\n",
       "2066     0          1\n",
       "2067     1          1\n",
       "2068     1          1\n",
       "2069     1          1\n",
       "2070     1          1\n",
       "\n",
       "[2071 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the sensitive feature - example: race\n",
    "A = pd.DataFrame(d, columns=['race', 'ethnicity'])\n",
    "A[\"race\"] = d[\"race\"].apply(lambda x:1 if x == 1 else 0)\n",
    "A[\"ethnicity\"] = d[\"ethnicity\"].apply(lambda x: 0 if x == 1 else 1)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904ae18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>Non-White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2071 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           race     ethnicity\n",
       "0         White  Non-Hispanic\n",
       "1         White  Non-Hispanic\n",
       "2         White      Hispanic\n",
       "3         White  Non-Hispanic\n",
       "4         White      Hispanic\n",
       "...         ...           ...\n",
       "2066  Non-White  Non-Hispanic\n",
       "2067      White  Non-Hispanic\n",
       "2068      White  Non-Hispanic\n",
       "2069      White  Non-Hispanic\n",
       "2070      White  Non-Hispanic\n",
       "\n",
       "[2071 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_str = A\n",
    "A_str[\"race\"] = A[\"race\"].map({ 1:\"White\", 0:\"Non-White\"})\n",
    "A_str[\"ethnicity\"] = A[\"ethnicity\"].map({1: \"Non-Hispanic\", 0:\"Hispanic\"})\n",
    "A_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d996aa14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the target\n",
    "y = d[\"action_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3412f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Now that we have imported our dataset and manufactured a few features, we\n",
    "# can perform some more conventional processing. To avoid the problem of\n",
    "# `data leakage <https://en.wikipedia.org/wiki/Leakage_(machine_learning)>`_,\n",
    "# we need to split the data into training and test sets before applying\n",
    "# any transforms or scaling:\n",
    "\n",
    "\n",
    "(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n",
    "    d.drop(columns=['action_taken']),\n",
    "    y, A_str, test_size=0.3, random_state=54321, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab7305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure indices are aligned between X, y and A,\n",
    "# after all the slicing and splitting of DataFrames\n",
    "# and Series\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "A_train = A_train.reset_index(drop=True)\n",
    "A_test = A_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f31f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Next, we build two :class:`~sklearn.pipeline.Pipeline` objects\n",
    "# to process the columns, one for numeric data, and the other\n",
    "# for categorical data. Both impute missing values; the difference\n",
    "# is whether the data are scaled (numeric columns) or\n",
    "# one-hot encoded (categorical columns). Imputation of missing\n",
    "# values should generally be done with care, since it could\n",
    "# potentially introduce biases. Of course, removing rows with\n",
    "# missing data could also cause trouble, if particular subgroups\n",
    "# have poorer data quality.\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0ae456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# With our preprocessor defined, we can now build a\n",
    "# new pipeline which includes an Estimator:\n",
    "\n",
    "unmitigated_predictor = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(solver=\"liblinear\", fit_intercept=True),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb50ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# With the pipeline fully defined, we can first train it\n",
    "# with the training data, and then generate predictions\n",
    "# from the test data.\n",
    "\n",
    "unmitigated_predictor.fit(X_train, y_train)\n",
    "y_pred = unmitigated_predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb99fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection Rate: 0.8762057877813505\n",
      "fbeta: 0.9006872090445579\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Analysing the Model with Metrics\n",
    "# ================================\n",
    "#\n",
    "# After our data manipulations and model training, we have the following\n",
    "# from our test set:\n",
    "#\n",
    "# - A vector of true values called ``y_test``\n",
    "# - A vector of model predictions called ``y_pred``\n",
    "# - A DataFrame of categorical features relevant to fairness called ``A_test``\n",
    "#\n",
    "# In a traditional model analysis, we would now look at some metrics\n",
    "# evaluated on the entire dataset. Suppose in this case, the relevant\n",
    "# metrics are :func:`fairlearn.metrics.selection_rate` and\n",
    "# :func:`sklearn.metrics.fbeta_score` (with\n",
    "# ``beta=0.6``).\n",
    "# We can evaluate these metrics directly:\n",
    "\n",
    "print(\"Selection Rate:\", selection_rate(y_test, y_pred))\n",
    "print(\"fbeta:\", skm.fbeta_score(y_test, y_pred, beta=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e614b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# We know that there are sensitive features in our data, and we want to\n",
    "# ensure that we're not harming individuals due to membership in any of\n",
    "# these groups. For this purpose, Fairlearn provides the\n",
    "# :class:`fairlearn.metrics.MetricFrame`\n",
    "# class. Let us construct an instance of this class, and then look at\n",
    "# its capabilities:\n",
    "\n",
    "fbeta_06 = functools.partial(skm.fbeta_score, beta=0.6)\n",
    "\n",
    "metric_fns = {'selection_rate': selection_rate, 'fbeta_06': fbeta_06, 'count': count}\n",
    "\n",
    "grouped_on_sex = MetricFrame(metrics=metric_fns,\n",
    "                             y_true=y_test,\n",
    "                             y_pred=y_pred,\n",
    "                             sensitive_features=A_test['race'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4147a4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selection_rate    0.876206\n",
      "fbeta_06          0.900687\n",
      "count                  622\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# The :class:`fairlearn.metrics.MetricFrame` object requires a\n",
    "# minimum of four arguments:\n",
    "#\n",
    "# 1. The underlying metric function(s) to be evaluated\n",
    "# 2. The true values\n",
    "# 3. The predicted values\n",
    "# 4. The sensitive feature values\n",
    "#\n",
    "# These are all passed as arguments to the constructor. If more than\n",
    "# one underlying metric is required (as in this case), then we must\n",
    "# provide them in a dictionary.\n",
    "#\n",
    "# The underlying metrics must have a signature ``fn(y_true, y_pred)``,\n",
    "# so we have to use :func:`functools.partial` on ``fbeta_score()`` to\n",
    "# furnish ``beta=0.6`` (we will show how to pass in extra array\n",
    "# arguments such as sample weights shortly).\n",
    "#\n",
    "# We will now take a closer look at the :class:`fairlearn.metrics.MetricFrame`\n",
    "# object. First, there is the ``overall`` property, which contains\n",
    "# the metrics evaluated on the entire dataset. We see that this contains the\n",
    "# same values calculated above:\n",
    "\n",
    "assert grouped_on_sex.overall['selection_rate'] == selection_rate(y_test, y_pred)\n",
    "assert grouped_on_sex.overall['fbeta_06'] == skm.fbeta_score(y_test, y_pred, beta=0.6)\n",
    "print(grouped_on_sex.overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8a27fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selection_rate</th>\n",
       "      <th>fbeta_06</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-White</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.868085</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.919847</td>\n",
       "      <td>0.905016</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          selection_rate  fbeta_06 count\n",
       "race                                    \n",
       "Non-White       0.642857  0.868085    98\n",
       "White           0.919847  0.905016   524"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# The other property in the :class:`fairlearn.metrics.MetricFrame` object\n",
    "# is ``by_group``. This contains the metrics evaluated on each subgroup defined\n",
    "# by the categories in the ``sensitive_features=`` argument. Note that\n",
    "# :func:`fairlearn.metrics.count` can be used to display the number of\n",
    "# data points in each subgroup. In this case, we have results for males and females:\n",
    "\n",
    "grouped_on_sex.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96e0bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# We can immediately see a substantial disparity in the selection rate between\n",
    "# males and females.\n",
    "#\n",
    "# We can also create another :class:`fairlearn.metrics.MetricFrame` object\n",
    "# using race as the sensitive feature:\n",
    "\n",
    "grouped_on_race = MetricFrame(metrics=metric_fns,\n",
    "                              y_true=y_test,\n",
    "                              y_pred=y_pred,\n",
    "                              sensitive_features=A_test['ethnicity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ca67ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# The ``overall`` property is unchanged:\n",
    "assert (grouped_on_sex.overall == grouped_on_race.overall).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fc2d18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selection_rate</th>\n",
       "      <th>fbeta_06</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.905569</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Hispanic</th>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.89991</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             selection_rate  fbeta_06 count\n",
       "ethnicity                                  \n",
       "Hispanic           0.815217  0.905569    92\n",
       "Non-Hispanic       0.886792   0.89991   530"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# The ``by_group`` property now contains the metrics evaluated based on the 'race'\n",
    "# column:\n",
    "grouped_on_race.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b92faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# We see that there is also a significant disparity in selection rates when\n",
    "# grouping by race.\n",
    "\n",
    "# %%\n",
    "# Sample weights and other arrays\n",
    "# -------------------------------\n",
    "#\n",
    "# We noted above that the underlying metric functions passed to the\n",
    "# :class:`fairlearn.metrics.MetricFrame` constructor need to be of\n",
    "# the form ``fn(y_true, y_pred)`` - we do not support scalar arguments\n",
    "# such as ``pos_label=`` or ``beta=`` in the constructor. Such\n",
    "# arguments should be bound into a new function using\n",
    "# :func:`functools.partial`, and the result passed in. However, we do\n",
    "# support arguments which have one entry for each sample, with an array\n",
    "# of sample weights being the most common example. These are divided\n",
    "# into subgroups along with ``y_true`` and ``y_pred``, and passed along\n",
    "# to the underlying metric.\n",
    "#\n",
    "# To use these arguments, we pass in a dictionary as the ``sample_params=``\n",
    "# argument of the constructor. Let us generate some random weights, and\n",
    "# pass these along:\n",
    "\n",
    "random_weights = np.random.rand(len(y_test))\n",
    "\n",
    "example_sample_params = {\n",
    "    'selection_rate': {'sample_weight': random_weights},\n",
    "    'fbeta_06': {'sample_weight': random_weights},\n",
    "}\n",
    "\n",
    "\n",
    "grouped_with_weights = MetricFrame(metrics=metric_fns,\n",
    "                                   y_true=y_test,\n",
    "                                   y_pred=y_pred,\n",
    "                                   sensitive_features=A_test['race'],\n",
    "                                   sample_params=example_sample_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f87a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selection_rate    0.88291\n",
      "fbeta_06          0.90609\n",
      "count                 622\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# We can inspect the overall values, and check they are as expected:\n",
    "assert grouped_with_weights.overall['selection_rate'] == \\\n",
    "    selection_rate(y_test, y_pred, sample_weight=random_weights)\n",
    "assert grouped_with_weights.overall['fbeta_06'] == \\\n",
    "    skm.fbeta_score(y_test, y_pred, beta=0.6, sample_weight=random_weights)\n",
    "print(grouped_with_weights.overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0213a95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selection_rate</th>\n",
       "      <th>fbeta_06</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-White</th>\n",
       "      <td>0.662692</td>\n",
       "      <td>0.889059</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.921341</td>\n",
       "      <td>0.90826</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          selection_rate  fbeta_06 count\n",
       "race                                    \n",
       "Non-White       0.662692  0.889059    98\n",
       "White           0.921341   0.90826   524"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# We can also see the effect on the metric being evaluated on the subgroups:\n",
    "grouped_with_weights.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2fa5ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selection_rate    0.815217\n",
       "fbeta_06           0.89991\n",
       "count                   92\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Quantifying Disparities\n",
    "# =======================\n",
    "#\n",
    "# We now know that our model is selecting individuals who are female far less\n",
    "# often than individuals who are male. There is a similar effect when\n",
    "# examining the results by race, with blacks being selected far less often than\n",
    "# whites (and those classified as 'other'). However, there are many cases where\n",
    "# presenting all these numbers at once will not be useful (for example, a high\n",
    "# level dashboard which is monitoring model performance). Fairlearn provides\n",
    "# several means of aggregating metrics across the subgroups, so that disparities\n",
    "# can be readily quantified.\n",
    "#\n",
    "# The simplest of these aggregations is ``group_min()``, which reports the\n",
    "# minimum value seen for a subgroup for each underlying metric (we also provide\n",
    "# ``group_max()``). This is\n",
    "# useful if there is a mandate that \"no subgroup should have an ``fbeta_score()``\n",
    "# of less than 0.6.\" We can evaluate the minimum values easily:\n",
    "grouped_on_race.group_min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eac22c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selection_rate    0.071575\n",
       "fbeta_06          0.005659\n",
       "count                  438\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# As noted above, the selection rates varies greatly by race and by sex.\n",
    "# This can be quantified in terms of a difference between the subgroup with\n",
    "# the highest value of the metric, and the subgroup with the lowest value.\n",
    "# For this, we provide the method ``difference(method='between_groups)``:\n",
    "grouped_on_race.difference(method='between_groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1928059c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selection_rate    0.060988\n",
       "fbeta_06          0.004882\n",
       "count                  530\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# We can also evaluate the difference relative to the corresponding overall\n",
    "# value of the metric. In this case we take the absolute value, so that the\n",
    "# result is always positive:\n",
    "grouped_on_race.difference(method='to_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eebef984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selection_rate    0.919288\n",
       "fbeta_06          0.993751\n",
       "count             0.173585\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# There are situations where knowing the ratios of the metrics evaluated on\n",
    "# the subgroups is more useful. For this we have the ``ratio()`` method.\n",
    "# We can take the ratios between the minimum and maximum values of each metric:\n",
    "grouped_on_race.ratio(method='between_groups')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09cbe0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selection_rate    0.930395\n",
       "fbeta_06          0.994609\n",
       "count             0.147910\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# We can also compute the ratios relative to the overall value for each\n",
    "# metric. Analogous to the differences, the ratios are always in the range\n",
    "# :math:`[0,1]`:\n",
    "grouped_on_race.ratio(method='to_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b0cfa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Intersections of Features\n",
    "# =========================\n",
    "#\n",
    "# So far we have only considered a single sensitive feature at a time,\n",
    "# and we have already found some serious issues in our example data.\n",
    "# However, sometimes serious issues can be hiding in intersections of\n",
    "# features. For example, the\n",
    "# `Gender Shades project <https://www.media.mit.edu/projects/gender-shades/overview/>`_\n",
    "# found that facial recognition algorithms performed worse for blacks\n",
    "# than whites, and also worse for women than men (despite overall high\n",
    "# accuracy score). Moreover, performance on black females was *terrible*.\n",
    "# We can examine the intersections of sensitive features by passing\n",
    "# multiple columns to the :class:`fairlearn.metrics.MetricFrame`\n",
    "# constructor:\n",
    "\n",
    "grouped_on_race_and_sex = MetricFrame(metrics=metric_fns,\n",
    "                                      y_true=y_test,\n",
    "                                      y_pred=y_pred,\n",
    "                                      sensitive_features=A_test[['race', 'ethnicity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10ca46df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>selection_rate</th>\n",
       "      <th>fbeta_06</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Non-White</th>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Hispanic</th>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.851359</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">White</th>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Hispanic</th>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.906567</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       selection_rate  fbeta_06 count\n",
       "race      ethnicity                                  \n",
       "Non-White Hispanic           0.583333       1.0    12\n",
       "          Non-Hispanic       0.651163  0.851359    86\n",
       "White     Hispanic               0.85  0.895536    80\n",
       "          Non-Hispanic       0.932432  0.906567   444"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# The overall values are unchanged, but the ``by_group`` table now\n",
    "# shows the intersections between subgroups:\n",
    "assert (grouped_on_race_and_sex.overall == grouped_on_race.overall).all()\n",
    "grouped_on_race_and_sex.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94df68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f01af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
